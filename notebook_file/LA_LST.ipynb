{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10186136,
          "sourceType": "datasetVersion",
          "datasetId": 5492444
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXCLyhSvzPQV",
        "outputId": "c96d2eb1-1f18-427e-e0b7-8b1369a01d7e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:09.923586Z",
          "iopub.execute_input": "2025-02-06T09:07:09.923929Z",
          "iopub.status.idle": "2025-02-06T09:07:12.471143Z",
          "shell.execute_reply.started": "2025-02-06T09:07:09.923900Z",
          "shell.execute_reply": "2025-02-06T09:07:12.470229Z"
        },
        "id": "ZbkMmjxQyG6D"
      },
      "outputs": [],
      "execution_count": 74
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "1gKtzodDyG6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/flowFeatures.csv', usecols=lambda x: x not in ['publicIP', 'FlowID', 'SrcPort', 'DstPort','Timestamp','Protocol', 'FlowDuration'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:12.837333Z",
          "iopub.execute_input": "2025-02-06T09:07:12.837726Z",
          "iopub.status.idle": "2025-02-06T09:07:31.334836Z",
          "shell.execute_reply.started": "2025-02-06T09:07:12.837701Z",
          "shell.execute_reply": "2025-02-06T09:07:31.334140Z"
        },
        "id": "HGjYHjqnyG6G"
      },
      "outputs": [],
      "execution_count": 75
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "PPs1mVKOyG6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['FlowPkts/s'] != np.inf]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:31.335918Z",
          "iopub.execute_input": "2025-02-06T09:07:31.336176Z",
          "iopub.status.idle": "2025-02-06T09:07:31.762731Z",
          "shell.execute_reply.started": "2025-02-06T09:07:31.336151Z",
          "shell.execute_reply": "2025-02-06T09:07:31.762061Z"
        },
        "id": "7ajr3FqSyG6G"
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": [
        "for col, cnt in df.isna().sum().items():\n",
        "  if cnt != 0:\n",
        "    print(f\"{col} have {cnt} null\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:31.763995Z",
          "iopub.execute_input": "2025-02-06T09:07:31.764296Z",
          "iopub.status.idle": "2025-02-06T09:07:32.091484Z",
          "shell.execute_reply.started": "2025-02-06T09:07:31.764260Z",
          "shell.execute_reply": "2025-02-06T09:07:32.090813Z"
        },
        "id": "8J7Q9eRnyG6H"
      },
      "outputs": [],
      "execution_count": 77
    },
    {
      "cell_type": "code",
      "source": [
        "for name, cnt in np.isinf(df.select_dtypes(exclude=[\"object\"])).sum().items():\n",
        "  if cnt != 0:\n",
        "    print(f\"{name} have {cnt} infinity\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:32.092692Z",
          "iopub.execute_input": "2025-02-06T09:07:32.092915Z",
          "iopub.status.idle": "2025-02-06T09:07:32.567425Z",
          "shell.execute_reply.started": "2025-02-06T09:07:32.092896Z",
          "shell.execute_reply": "2025-02-06T09:07:32.566466Z"
        },
        "id": "xl1v3Bo_yG6H"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "  if len(df[col].unique()) == 1:\n",
        "    df.drop(col, axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:32.568404Z",
          "iopub.execute_input": "2025-02-06T09:07:32.568735Z",
          "iopub.status.idle": "2025-02-06T09:07:38.031279Z",
          "shell.execute_reply.started": "2025-02-06T09:07:32.568704Z",
          "shell.execute_reply": "2025-02-06T09:07:38.030608Z"
        },
        "id": "WFGJ1odRyG6H"
      },
      "outputs": [],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:38.032091Z",
          "iopub.execute_input": "2025-02-06T09:07:38.032365Z",
          "iopub.status.idle": "2025-02-06T09:07:42.069350Z",
          "shell.execute_reply.started": "2025-02-06T09:07:38.032343Z",
          "shell.execute_reply": "2025-02-06T09:07:42.068422Z"
        },
        "id": "ptmGManiyG6H"
      },
      "outputs": [],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:42.070271Z",
          "iopub.execute_input": "2025-02-06T09:07:42.070603Z",
          "iopub.status.idle": "2025-02-06T09:07:42.076228Z",
          "shell.execute_reply.started": "2025-02-06T09:07:42.070571Z",
          "shell.execute_reply": "2025-02-06T09:07:42.075613Z"
        },
        "id": "2HTfNQGkyG6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffe174f-679d-4eca-f5c7-9e7c6c4883a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1295864, 66)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "execution_count": 81
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data handling"
      ],
      "metadata": {
        "id": "IgQPygiJyG6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ip_pair(src_ip, dst_ip):\n",
        "    return tuple(sorted([src_ip, dst_ip]))\n",
        "\n",
        "# Tạo cặp IP đã sort cho việc nhóm\n",
        "ip_pairs = [create_ip_pair(src, dst) for src, dst in zip(df['SrcIP'], df['DstIP'])]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:42.078070Z",
          "iopub.execute_input": "2025-02-06T09:07:42.078304Z",
          "iopub.status.idle": "2025-02-06T09:07:42.752353Z",
          "shell.execute_reply.started": "2025-02-06T09:07:42.078285Z",
          "shell.execute_reply": "2025-02-06T09:07:42.751525Z"
        },
        "id": "eM32cYCMyG6I"
      },
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": [
        "lenpairs = set(ip_pairs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:42.753560Z",
          "iopub.execute_input": "2025-02-06T09:07:42.753774Z",
          "iopub.status.idle": "2025-02-06T09:07:42.820026Z",
          "shell.execute_reply.started": "2025-02-06T09:07:42.753756Z",
          "shell.execute_reply": "2025-02-06T09:07:42.819196Z"
        },
        "id": "bizNUsRbyG6J"
      },
      "outputs": [],
      "execution_count": 83
    },
    {
      "cell_type": "code",
      "source": [
        "# Chọn các cột số để train\n",
        "numerical_columns = [col for col in df.columns\n",
        "                    if col not in ['Label', 'SrcIP', 'DstIP']\n",
        "                    and df[col].dtype in ['int64', 'float64']]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:42.842636Z",
          "iopub.execute_input": "2025-02-06T09:07:42.842929Z",
          "iopub.status.idle": "2025-02-06T09:07:42.856928Z",
          "shell.execute_reply.started": "2025-02-06T09:07:42.842900Z",
          "shell.execute_reply": "2025-02-06T09:07:42.856263Z"
        },
        "id": "cdSCY6FsyG6J"
      },
      "outputs": [],
      "execution_count": 84
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Chuẩn bị features\n",
        "X = df[numerical_columns]\n",
        "y = df['Label']\n",
        "\n",
        "# Split data và thêm ip_pairs vào để nhóm sau này\n",
        "X_train, X_test, y_train, y_test, pairs_train, pairs_test = train_test_split(\n",
        "    X, y, ip_pairs, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:42.857721Z",
          "iopub.execute_input": "2025-02-06T09:07:42.858010Z",
          "iopub.status.idle": "2025-02-06T09:07:45.314417Z",
          "shell.execute_reply.started": "2025-02-06T09:07:42.857982Z",
          "shell.execute_reply": "2025-02-06T09:07:45.313730Z"
        },
        "id": "WSVbR5uzyG6J"
      },
      "outputs": [],
      "execution_count": 85
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:45.315236Z",
          "iopub.execute_input": "2025-02-06T09:07:45.315466Z",
          "iopub.status.idle": "2025-02-06T09:07:46.584085Z",
          "shell.execute_reply.started": "2025-02-06T09:07:45.315446Z",
          "shell.execute_reply": "2025-02-06T09:07:46.583191Z"
        },
        "id": "yrqJS8_GyG6J"
      },
      "outputs": [],
      "execution_count": 86
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.shape, y_train.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:46.584987Z",
          "iopub.execute_input": "2025-02-06T09:07:46.585232Z",
          "iopub.status.idle": "2025-02-06T09:07:46.590273Z",
          "shell.execute_reply.started": "2025-02-06T09:07:46.585211Z",
          "shell.execute_reply": "2025-02-06T09:07:46.589389Z"
        },
        "id": "5M4Ymv8OyG6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58744a19-d13f-40fe-87de-e17d5c2d4e9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1036691, 63), (1036691,))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:46.590976Z",
          "iopub.execute_input": "2025-02-06T09:07:46.591216Z",
          "iopub.status.idle": "2025-02-06T09:07:46.650656Z",
          "shell.execute_reply.started": "2025-02-06T09:07:46.591197Z",
          "shell.execute_reply": "2025-02-06T09:07:46.649964Z"
        },
        "id": "5lJ4L6ynyG6J"
      },
      "outputs": [],
      "execution_count": 88
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create sequences"
      ],
      "metadata": {
        "id": "5WIpcVSByG6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IPFlowDataset(Dataset):\n",
        "    def __init__(self, X, y, ip_pairs, max_flows=100):\n",
        "        self.max_flows = max_flows\n",
        "        self.sequences = []\n",
        "        self.labels = []\n",
        "        self.lengths = []\n",
        "\n",
        "        # Convert to numpy for faster processing\n",
        "        X_np = X if isinstance(X, np.ndarray) else X.values\n",
        "        y_np = y.values if hasattr(y, 'values') else np.array(y)\n",
        "\n",
        "        # Group by IP pairs\n",
        "        unique_pairs = set(ip_pairs)\n",
        "        print(f\"Number of unique IP pairs: {len(unique_pairs)}\")\n",
        "\n",
        "        for pair in unique_pairs:\n",
        "            indices = [i for i, p in enumerate(ip_pairs) if p == pair]\n",
        "\n",
        "            if len(indices) > 0:\n",
        "                flows = X_np[indices]\n",
        "                flow_labels = y_np[indices]\n",
        "\n",
        "                # Tìm vị trí của các flows APT\n",
        "                apt_indices = [i for i, label in enumerate(flow_labels) if label == \"APT\"]\n",
        "\n",
        "                selected_indices = []\n",
        "                if len(apt_indices) > 0.15*max_flows:  # Nếu có flows APT\n",
        "                    # Đảm bảo lấy tất cả flows APT nếu có thể\n",
        "                    if len(apt_indices) <= max_flows:\n",
        "                        selected_indices.extend(apt_indices)\n",
        "\n",
        "                        # Số lượng flows còn có thể thêm vào\n",
        "                        remaining_slots = max_flows - len(selected_indices)\n",
        "\n",
        "                        # Lấy flows xung quanh APT flows\n",
        "                        surrounding_indices = set()\n",
        "                        for apt_idx in apt_indices:\n",
        "                            window = 10  # Số flows trước và sau mỗi APT flow\n",
        "                            start = max(0, apt_idx - window)\n",
        "                            end = min(len(flows), apt_idx + window + 1)\n",
        "                            surrounding_indices.update(range(start, end))\n",
        "\n",
        "                        # Loại bỏ các APT indices đã có\n",
        "                        surrounding_indices = surrounding_indices - set(apt_indices)\n",
        "\n",
        "                        # Thêm flows xung quanh\n",
        "                        if surrounding_indices:\n",
        "                            n_surrounding = min(remaining_slots, len(surrounding_indices))\n",
        "                            selected_indices.extend(\n",
        "                                np.random.choice(list(surrounding_indices),\n",
        "                                               size=n_surrounding,\n",
        "                                               replace=False)\n",
        "                            )\n",
        "\n",
        "                        # Nếu vẫn còn slots, thêm flows ngẫu nhiên\n",
        "                        remaining_slots = max_flows - len(selected_indices)\n",
        "                        if remaining_slots > 0:\n",
        "                            remaining_indices = list(set(range(len(flows))) -\n",
        "                                                   set(selected_indices))\n",
        "                            if remaining_indices:\n",
        "                                selected_indices.extend(\n",
        "                                    np.random.choice(remaining_indices,\n",
        "                                                   size=remaining_slots,\n",
        "                                                   replace=False)\n",
        "                                )\n",
        "                    else:\n",
        "                        # Nếu có quá nhiều APT flows, lấy ngẫu nhiên từ các APT flows\n",
        "                        selected_indices = list(np.random.choice(apt_indices,\n",
        "                                                              size=max_flows,\n",
        "                                                              replace=False))\n",
        "                else:\n",
        "                    # Nếu không có flows APT, lấy ngẫu nhiên\n",
        "                    if len(flows) > max_flows:\n",
        "                        selected_indices = list(np.random.choice(len(flows),\n",
        "                                                              size=max_flows,\n",
        "                                                              replace=False))\n",
        "                    else:\n",
        "                        selected_indices = list(range(len(flows)))\n",
        "\n",
        "                # Sort indices\n",
        "                selected_indices = sorted(selected_indices)\n",
        "\n",
        "                # Lấy selected flows\n",
        "                if len(selected_indices) > max_flows:\n",
        "                    selected_indices = selected_indices[:max_flows]\n",
        "\n",
        "                selected_flows = flows[selected_indices]\n",
        "                length = len(selected_flows)\n",
        "\n",
        "                # Pad nếu cần\n",
        "                if length < max_flows:\n",
        "                    padding = np.zeros((max_flows - length, flows.shape[1]))\n",
        "                    selected_flows = np.vstack([selected_flows, padding])\n",
        "                elif length > max_flows:\n",
        "                    selected_flows = selected_flows[:max_flows]\n",
        "                    length = max_flows\n",
        "\n",
        "                self.sequences.append(selected_flows)\n",
        "                self.labels.append(1 if len(apt_indices) >= 0.1*max_flows else 0)\n",
        "                self.lengths.append(length)\n",
        "\n",
        "        print(f\"Total sequences: {len(self.sequences)}\")\n",
        "        print(f\"APT sequences: {sum(self.labels)}\")\n",
        "\n",
        "        # Convert to tensors\n",
        "        self.sequences = torch.FloatTensor(np.array(self.sequences))\n",
        "        self.labels = torch.FloatTensor(self.labels)\n",
        "        self.lengths = torch.LongTensor(self.lengths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.sequences[idx],\n",
        "            self.labels[idx],\n",
        "            self.lengths[idx]\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:46.723293Z",
          "iopub.execute_input": "2025-02-06T09:07:46.723549Z",
          "iopub.status.idle": "2025-02-06T09:07:46.738377Z",
          "shell.execute_reply.started": "2025-02-06T09:07:46.723516Z",
          "shell.execute_reply": "2025-02-06T09:07:46.737511Z"
        },
        "id": "KpP_v59xyG6K"
      },
      "outputs": [],
      "execution_count": 89
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data loaders for training"
      ],
      "metadata": {
        "id": "psydGa_LyG6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = IPFlowDataset(X_train_scaled, y_train, pairs_train)\n",
        "test_dataset = IPFlowDataset(X_test_scaled, y_test, pairs_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:07:46.739224Z",
          "iopub.execute_input": "2025-02-06T09:07:46.739504Z",
          "iopub.status.idle": "2025-02-06T09:13:24.829936Z",
          "shell.execute_reply.started": "2025-02-06T09:07:46.739483Z",
          "shell.execute_reply": "2025-02-06T09:13:24.829082Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j8U0-V6yG6K",
        "outputId": "412342d0-778c-4913-9b34-05796d6f0ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IP pairs: 1804\n",
            "Total sequences: 1804\n",
            "APT sequences: 217\n",
            "Number of unique IP pairs: 1270\n",
            "Total sequences: 1270\n",
            "APT sequences: 211\n"
          ]
        }
      ],
      "execution_count": 90
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN for generating balanced APT sequences"
      ],
      "metadata": {
        "id": "cEsZvbi4yG6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, feature_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Layer 2\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Layer 3\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Output layer\n",
        "            nn.Linear(1024, feature_dim),\n",
        "            nn.Tanh()  # Normalize outputs to [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.model(noise)"
      ],
      "metadata": {
        "id": "h51gQx_vqeoQ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, features):\n",
        "        return self.model(features)"
      ],
      "metadata": {
        "id": "sKZRNMORqr71"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(generator, discriminator, train_dataset, n_epochs=100, batch_size=32):\n",
        "    # Hyperparameters\n",
        "    latent_dim = 100\n",
        "    lr = 0.0001\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "\n",
        "    # Optimizers\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "    # Loss function\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "\n",
        "    # Prepare real APT sequences\n",
        "    apt_sequences = []\n",
        "    apt_lengths = []\n",
        "    for i in range(len(train_dataset)):\n",
        "        if train_dataset.labels[i] == 1:\n",
        "            apt_sequences.append(train_dataset.sequences[i])\n",
        "            apt_lengths.append(train_dataset.lengths[i])\n",
        "\n",
        "    apt_sequences = torch.stack(apt_sequences)\n",
        "    apt_lengths = torch.stack(apt_lengths)\n",
        "\n",
        "    n_apt = len(apt_sequences)\n",
        "    print(f\"Number of real APT sequences: {n_apt}\")\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(n_epochs):\n",
        "        for i in range(0, n_apt, batch_size):\n",
        "            batch_size_i = min(batch_size, n_apt - i)\n",
        "\n",
        "            # Configure input\n",
        "            real_seqs = apt_sequences[i:i+batch_size_i].to(device)\n",
        "            real_lengths = apt_lengths[i:i+batch_size_i].to(device)\n",
        "\n",
        "            # Create labels\n",
        "            valid = torch.ones((batch_size_i, 1)).to(device)\n",
        "            fake = torch.zeros((batch_size_i, 1)).to(device)\n",
        "\n",
        "            # Generate a batch of sequences\n",
        "            noise = torch.randn(batch_size_i, latent_dim).to(device)\n",
        "            labels = torch.ones((batch_size_i, 1)).to(device)  # All APT\n",
        "\n",
        "            # Generate fake sequences\n",
        "            gen_seqs = generator(noise)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            real_loss = adversarial_loss(discriminator(real_seqs.view(batch_size_i, -1)), valid)\n",
        "            fake_loss = adversarial_loss(discriminator(gen_seqs.detach()), fake)\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            g_loss = adversarial_loss(discriminator(gen_seqs), valid)\n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"[Epoch {epoch+1}/{n_epochs}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
        "\n",
        "    return generator"
      ],
      "metadata": {
        "id": "tTwKJU_LqzNH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize và train GAN\n",
        "latent_dim = 100\n",
        "feature_dim = train_dataset.sequences.size(-1) * train_dataset.sequences.size(1)  # Total features in a sequence\n",
        "generator = Generator(latent_dim, feature_dim).to(device)\n",
        "discriminator = Discriminator(feature_dim).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:21:26.432233Z",
          "iopub.execute_input": "2025-02-06T09:21:26.432507Z",
          "iopub.status.idle": "2025-02-06T09:21:26.712583Z",
          "shell.execute_reply.started": "2025-02-06T09:21:26.432488Z",
          "shell.execute_reply": "2025-02-06T09:21:26.711700Z"
        },
        "id": "_fDVPVY3yG6L"
      },
      "outputs": [],
      "execution_count": 94
    },
    {
      "cell_type": "code",
      "source": [
        "# Train GAN\n",
        "generator = train_gan(generator, discriminator, train_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:21:28.315735Z",
          "iopub.execute_input": "2025-02-06T09:21:28.316055Z",
          "iopub.status.idle": "2025-02-06T09:21:33.970794Z",
          "shell.execute_reply.started": "2025-02-06T09:21:28.316028Z",
          "shell.execute_reply": "2025-02-06T09:21:33.970029Z"
        },
        "id": "7hnFSXo3yG6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c823a3a3-768c-4fcb-ce22-b2853e6d0ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of real APT sequences: 217\n",
            "[Epoch 10/100] [D loss: 0.6109] [G loss: 0.8128]\n",
            "[Epoch 20/100] [D loss: 0.5044] [G loss: 0.9388]\n",
            "[Epoch 30/100] [D loss: 0.5968] [G loss: 0.8191]\n",
            "[Epoch 40/100] [D loss: 0.6287] [G loss: 0.7825]\n",
            "[Epoch 50/100] [D loss: 0.5102] [G loss: 0.8437]\n",
            "[Epoch 60/100] [D loss: 0.5447] [G loss: 0.9759]\n",
            "[Epoch 70/100] [D loss: 0.6030] [G loss: 0.8838]\n",
            "[Epoch 80/100] [D loss: 0.5868] [G loss: 0.9900]\n",
            "[Epoch 90/100] [D loss: 0.5887] [G loss: 1.0238]\n",
            "[Epoch 100/100] [D loss: 0.4906] [G loss: 1.0447]\n"
          ]
        }
      ],
      "execution_count": 95
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic APT sequences\n",
        "n_synthetic = int(len(train_dataset.sequences) - 2 * sum(train_dataset.labels).item())  # Convert to integer\n",
        "print(f\"Generating {n_synthetic} synthetic sequences\")\n",
        "\n",
        "noise = torch.randn(n_synthetic, latent_dim).to(device)\n",
        "# labels = torch.ones((n_synthetic, 1)).to(device) #CGAN"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:21:35.793894Z",
          "iopub.execute_input": "2025-02-06T09:21:35.794440Z",
          "iopub.status.idle": "2025-02-06T09:21:35.808081Z",
          "shell.execute_reply.started": "2025-02-06T09:21:35.794403Z",
          "shell.execute_reply": "2025-02-06T09:21:35.807348Z"
        },
        "id": "nVXf3vxJyG6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad50d88-b636-4f0a-a22b-391f29698b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 1370 synthetic sequences\n"
          ]
        }
      ],
      "execution_count": 96
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    # gen_seqs = generator(noise, labels) #CGAN\n",
        "    gen_seqs = generator(noise) #GAN\n",
        "    gen_seqs = gen_seqs.view(n_synthetic, train_dataset.sequences.size(1), -1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:21:37.585582Z",
          "iopub.execute_input": "2025-02-06T09:21:37.585906Z",
          "iopub.status.idle": "2025-02-06T09:21:37.591200Z",
          "shell.execute_reply.started": "2025-02-06T09:21:37.585879Z",
          "shell.execute_reply": "2025-02-06T09:21:37.590589Z"
        },
        "id": "pEbK7v_ZyG6L"
      },
      "outputs": [],
      "execution_count": 97
    },
    {
      "cell_type": "code",
      "source": [
        "# Add synthetic sequences to training data\n",
        "train_dataset.sequences = torch.cat([train_dataset.sequences, gen_seqs.cpu()], dim=0)\n",
        "train_dataset.labels = torch.cat([train_dataset.labels, torch.ones(n_synthetic)], dim=0)\n",
        "train_dataset.lengths = torch.cat([train_dataset.lengths, torch.full((n_synthetic,), train_dataset.sequences.size(1), dtype=torch.long)], dim=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:21:39.122602Z",
          "iopub.execute_input": "2025-02-06T09:21:39.122918Z",
          "iopub.status.idle": "2025-02-06T09:21:39.145273Z",
          "shell.execute_reply.started": "2025-02-06T09:21:39.122893Z",
          "shell.execute_reply": "2025-02-06T09:21:39.144569Z"
        },
        "id": "BQ7sJzOhyG6L"
      },
      "outputs": [],
      "execution_count": 98
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:21:40.645537Z",
          "iopub.execute_input": "2025-02-06T09:21:40.645868Z",
          "iopub.status.idle": "2025-02-06T09:21:40.650073Z",
          "shell.execute_reply.started": "2025-02-06T09:21:40.645841Z",
          "shell.execute_reply": "2025-02-06T09:21:40.649221Z"
        },
        "id": "xb81GMu8yG6L"
      },
      "outputs": [],
      "execution_count": 99
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM + Switch Transformer"
      ],
      "metadata": {
        "id": "TMnAVArTX8DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Expert(nn.Module):\n",
        "  def __init__(self, d_model, hidden_dim):\n",
        "    super(Expert, self).__init__()\n",
        "    self.input_projection = nn.Linear(d_model, hidden_dim)\n",
        "    self.output_projection = nn.Linear(hidden_dim, d_model)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input_projection(x))\n",
        "    return self.output_projection(x)"
      ],
      "metadata": {
        "id": "LwVuTH5oX7dP"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingNetwork(nn.Module):\n",
        "  def __init__(self, d_model, num_experts):\n",
        "    super(GatingNetwork, self).__init__()\n",
        "    self.gate = nn.Linear(d_model, num_experts)\n",
        "  def forward(self, x):\n",
        "    return F.softmax(self.gate(x), dim=-1)"
      ],
      "metadata": {
        "id": "NMqbuIB-brlx"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MoELayer(nn.Module):\n",
        "  def __init__(self, d_model, hidden_dim, num_experts, top_k=2):\n",
        "    super(MoELayer, self).__init__()\n",
        "    self.experts = nn.ModuleList([Expert(d_model, hidden_dim) for _ in range(num_experts)])\n",
        "    self.gate = GatingNetwork(d_model, num_experts)\n",
        "    self.num_experts = num_experts\n",
        "    self.top_k = top_k\n",
        "  def forward(self, x):\n",
        "    batch_size, seq_len, d_model = x.shape\n",
        "    gating_scores = self.gate(x)\n",
        "    top_k_scores, top_k_indices = torch.topk(gating_scores, self.top_k, dim=-1)\n",
        "    top_k_scores_normalized = top_k_scores / top_k_scores.sum(dim=-1, keepdim=True)\n",
        "\n",
        "    output = torch.zeros_like(x)\n",
        "    for i in range(self.num_experts):\n",
        "      mask = (top_k_indices == i).float()\n",
        "      if mask.any():\n",
        "        position_using_expert = mask.any(dim=-1)\n",
        "        if position_using_expert.any():\n",
        "          expert_input = x[position_using_expert]\n",
        "          expert_output = self.experts[i](expert_input)\n",
        "          expert_weights = torch.zeros(batch_size, seq_len, device=x.device)\n",
        "          for k in range(self.top_k):\n",
        "            mask_k = (top_k_indices[..., k] == i)\n",
        "            expert_weights[mask_k] = top_k_scores[..., k][mask_k]\n",
        "          weighted_output = torch.zeros_like(x, dtype=expert_output.dtype)\n",
        "          weighted_output[position_using_expert] = expert_output\n",
        "          output += weighted_output * expert_weights.unsqueeze(-1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "vZyP8nEkbtVo"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwitchTransformer(nn.Module):\n",
        "  def __init__(self, d_model, nhead, num_experts, hidden_dim, dropout=0.1, top_k=2, batch_first=False):\n",
        "    super(SwitchTransformer, self).__init__()\n",
        "    self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first)\n",
        "    self.moe = MoELayer(d_model, hidden_dim, num_experts, top_k=top_k)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "  def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
        "    src2 = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
        "    src = src + self.dropout(src2)\n",
        "    src = self.norm1(src)\n",
        "    src2 = self.moe(src)\n",
        "    src = src + self.dropout(src2)\n",
        "    src = self.norm2(src)\n",
        "    return src"
      ],
      "metadata": {
        "id": "gbTuUUXMygAF"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ELModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=128):\n",
        "        super(ELModel, self).__init__()\n",
        "\n",
        "        # Feature Extraction\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            dropout=0.3\n",
        "        )\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = SwitchTransformer(\n",
        "            d_model=hidden_size,\n",
        "            nhead=8,\n",
        "            num_experts=5,\n",
        "            hidden_dim=hidden_size,\n",
        "            dropout=0.3,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        batch_size = x.size(0)\n",
        "        seq_len = x.size(1)\n",
        "\n",
        "        # Feature extraction\n",
        "        x = self.feature_extractor(x)  # (batch, seq_len, hidden_size)\n",
        "\n",
        "        # Sort sequences by length for packed sequence\n",
        "        lengths_cpu = lengths.cpu()\n",
        "        lengths_sorted, indices = torch.sort(lengths_cpu, descending=True)\n",
        "        x_sorted = x[indices]\n",
        "\n",
        "        # Pack sequence for LSTM\n",
        "        packed_x = nn.utils.rnn.pack_padded_sequence(\n",
        "            x_sorted, lengths_sorted, batch_first=True\n",
        "        )\n",
        "\n",
        "        # BiLSTM\n",
        "        lstm_out, _ = self.lstm(packed_x)\n",
        "\n",
        "        # Unpack LSTM output\n",
        "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n",
        "            lstm_out, batch_first=True, total_length=seq_len\n",
        "        )\n",
        "\n",
        "        # Restore original order\n",
        "        _, restore_indices = torch.sort(indices)\n",
        "        lstm_out = lstm_out[restore_indices]\n",
        "\n",
        "        # Create attention mask for transformer\n",
        "        # False indicates valid position, True indicates padding\n",
        "        key_padding_mask = torch.arange(seq_len).unsqueeze(0).expand(batch_size, -1).to(x.device)\n",
        "        key_padding_mask = key_padding_mask >= lengths.unsqueeze(-1)\n",
        "\n",
        "        # Transformer encoding\n",
        "        transformer_out = self.transformer(\n",
        "            lstm_out,\n",
        "            src_key_padding_mask=key_padding_mask\n",
        "        )  # (batch, seq_len, hidden_size)\n",
        "\n",
        "        # Mask out padding before pooling\n",
        "        mask = (~key_padding_mask).float().unsqueeze(-1)\n",
        "        transformer_out = transformer_out * mask\n",
        "\n",
        "        # Global average pooling over sequence length\n",
        "        # First transpose to get sequence length at the last dimension\n",
        "        pooled = transformer_out.sum(dim=1) / lengths.float().unsqueeze(-1)\n",
        "\n",
        "        # Classification\n",
        "        return self.classifier(pooled)\n"
      ],
      "metadata": {
        "id": "k4FYcSQcz_H_"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.cuda.amp.autocast()\n",
        "def train_epoch(model, train_loader, criterion, optimizer, scaler):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_flows, batch_labels, batch_lengths in train_loader:\n",
        "        batch_flows = batch_flows.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        batch_lengths = batch_lengths.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(batch_flows, batch_lengths)\n",
        "            outputs = outputs.view(-1)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs.detach())\n",
        "        preds = (preds > 0.5).float()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "    return {\n",
        "        'loss': total_loss / len(train_loader),\n",
        "        'accuracy': accuracy_score(all_labels, all_preds),\n",
        "        'precision': precision_score(all_labels, all_preds),\n",
        "        'recall': recall_score(all_labels, all_preds),\n",
        "        'f1': f1_score(all_labels, all_preds)\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_flows, batch_labels, batch_lengths in test_loader:\n",
        "        batch_flows = batch_flows.to(device)\n",
        "        batch_lengths = batch_lengths.to(device)\n",
        "\n",
        "        outputs = model(batch_flows, batch_lengths)\n",
        "        outputs = outputs.view(-1)\n",
        "\n",
        "        preds = torch.sigmoid(outputs)\n",
        "        preds = (preds > 0.5).float()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_labels.numpy())\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(all_labels, all_preds),\n",
        "        'precision': precision_score(all_labels, all_preds),\n",
        "        'recall': recall_score(all_labels, all_preds),\n",
        "        'f1': f1_score(all_labels, all_preds)\n",
        "    }\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=10):\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.0]).to(device))\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=0.0001,\n",
        "        weight_decay=0.01\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    best_f1 = 0\n",
        "    patience = 10\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
        "\n",
        "        # Evaluate\n",
        "        test_metrics = evaluate(model, test_loader)\n",
        "\n",
        "        # Early stopping\n",
        "        if test_metrics['f1'] > best_f1:\n",
        "            best_f1 = test_metrics['f1']\n",
        "            best_state = model.state_dict()\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= patience:\n",
        "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "            model.load_state_dict(best_state)\n",
        "            break\n",
        "\n",
        "        # Print metrics\n",
        "        print(f'\\nEpoch {epoch+1}/{epochs}')\n",
        "        print(f'Train - Loss: {train_metrics[\"loss\"]:.4f}, Acc: {train_metrics[\"accuracy\"]:.4f}, '\n",
        "              f'Prec: {train_metrics[\"precision\"]:.4f}, Rec: {train_metrics[\"recall\"]:.4f}, '\n",
        "              f'F1: {train_metrics[\"f1\"]:.4f}')\n",
        "        print(f'Test  - Acc: {test_metrics[\"accuracy\"]:.4f}, Prec: {test_metrics[\"precision\"]:.4f}, '\n",
        "              f'Rec: {test_metrics[\"recall\"]:.4f}, F1: {test_metrics[\"f1\"]:.4f}')\n",
        "\n",
        "    # Final evaluation\n",
        "    model.eval()\n",
        "    final_metrics = evaluate(model, test_loader)\n",
        "    print(\"\\nFinal Test Results:\")\n",
        "    print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {final_metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {final_metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score: {final_metrics['f1']:.4f}\")\n",
        "\n",
        "    return model, final_metrics"
      ],
      "metadata": {
        "id": "zJRq8IRP7B0E"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluate"
      ],
      "metadata": {
        "id": "OR3L4kdlyG6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "input_size = X_train_scaled.shape[1]  # Số features gốc\n",
        "model = ELModel(input_size).to(device)\n",
        "\n",
        "# Train model với các hàm train_epoch và evaluate đã có\n",
        "train_model(model, train_loader, test_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:33:44.327650Z",
          "iopub.execute_input": "2025-02-06T09:33:44.327946Z",
          "iopub.status.idle": "2025-02-06T09:34:42.744995Z",
          "shell.execute_reply.started": "2025-02-06T09:33:44.327923Z",
          "shell.execute_reply": "2025-02-06T09:34:42.744135Z"
        },
        "id": "3nLBtGIYyG6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcecaa1-5c2c-4466-d94f-b8fd9100607c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train - Loss: 0.6839, Acc: 0.7127, Prec: 0.6355, Rec: 0.9975, F1: 0.7764\n",
            "Test  - Acc: 0.9598, Prec: 0.8279, Rec: 0.9573, F1: 0.8879\n",
            "\n",
            "Epoch 2/10\n",
            "Train - Loss: 0.1313, Acc: 0.9849, Prec: 0.9730, Rec: 0.9975, F1: 0.9851\n",
            "Test  - Acc: 0.9882, Prec: 0.9455, Rec: 0.9858, F1: 0.9652\n",
            "\n",
            "Epoch 3/10\n",
            "Train - Loss: 0.0606, Acc: 0.9934, Prec: 0.9882, Rec: 0.9987, F1: 0.9934\n",
            "Test  - Acc: 0.9953, Prec: 0.9724, Rec: 1.0000, F1: 0.9860\n",
            "\n",
            "Epoch 4/10\n",
            "Train - Loss: 0.0368, Acc: 0.9978, Prec: 0.9962, Rec: 0.9994, F1: 0.9978\n",
            "Test  - Acc: 0.9976, Prec: 0.9860, Rec: 1.0000, F1: 0.9929\n",
            "\n",
            "Epoch 5/10\n",
            "Train - Loss: 0.0284, Acc: 0.9984, Prec: 0.9969, Rec: 1.0000, F1: 0.9984\n",
            "Test  - Acc: 0.9976, Prec: 0.9906, Rec: 0.9953, F1: 0.9929\n",
            "\n",
            "Epoch 6/10\n",
            "Train - Loss: 0.0235, Acc: 0.9987, Prec: 0.9975, Rec: 1.0000, F1: 0.9987\n",
            "Test  - Acc: 0.9984, Prec: 0.9906, Rec: 1.0000, F1: 0.9953\n",
            "\n",
            "Epoch 7/10\n",
            "Train - Loss: 0.0203, Acc: 0.9978, Prec: 0.9962, Rec: 0.9994, F1: 0.9978\n",
            "Test  - Acc: 0.9984, Prec: 0.9906, Rec: 1.0000, F1: 0.9953\n",
            "\n",
            "Epoch 8/10\n",
            "Train - Loss: 0.0167, Acc: 0.9987, Prec: 0.9981, Rec: 0.9994, F1: 0.9987\n",
            "Test  - Acc: 0.9969, Prec: 0.9814, Rec: 1.0000, F1: 0.9906\n",
            "\n",
            "Epoch 9/10\n",
            "Train - Loss: 0.0163, Acc: 0.9981, Prec: 0.9962, Rec: 1.0000, F1: 0.9981\n",
            "Test  - Acc: 0.9969, Prec: 0.9905, Rec: 0.9905, F1: 0.9905\n",
            "\n",
            "Epoch 10/10\n",
            "Train - Loss: 0.0147, Acc: 0.9984, Prec: 0.9975, Rec: 0.9994, F1: 0.9984\n",
            "Test  - Acc: 0.9961, Prec: 0.9905, Rec: 0.9858, F1: 0.9881\n",
            "\n",
            "Final Test Results:\n",
            "Accuracy: 0.9961\n",
            "Precision: 0.9905\n",
            "Recall: 0.9858\n",
            "F1 Score: 0.9881\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ELModel(\n",
              "   (feature_extractor): Sequential(\n",
              "     (0): Linear(in_features=63, out_features=128, bias=True)\n",
              "     (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "     (2): ReLU()\n",
              "     (3): Dropout(p=0.3, inplace=False)\n",
              "   )\n",
              "   (lstm): LSTM(128, 128, batch_first=True, dropout=0.3)\n",
              "   (transformer): TransformerEncoder(\n",
              "     (layers): ModuleList(\n",
              "       (0): SwitchTransformer(\n",
              "         (self_attn): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "         )\n",
              "         (moe): MoELayer(\n",
              "           (experts): ModuleList(\n",
              "             (0-4): 5 x Expert(\n",
              "               (input_projection): Linear(in_features=128, out_features=128, bias=True)\n",
              "               (output_projection): Linear(in_features=128, out_features=128, bias=True)\n",
              "             )\n",
              "           )\n",
              "           (gate): GatingNetwork(\n",
              "             (gate): Linear(in_features=128, out_features=5, bias=True)\n",
              "           )\n",
              "         )\n",
              "         (dropout): Dropout(p=0.3, inplace=False)\n",
              "         (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "         (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "       )\n",
              "     )\n",
              "   )\n",
              "   (classifier): Sequential(\n",
              "     (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "     (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "     (2): ReLU()\n",
              "     (3): Dropout(p=0.3, inplace=False)\n",
              "     (4): Linear(in_features=128, out_features=1, bias=True)\n",
              "   )\n",
              " ),\n",
              " {'accuracy': 0.9960629921259843,\n",
              "  'precision': 0.9904761904761905,\n",
              "  'recall': 0.985781990521327,\n",
              "  'f1': 0.9881235154394299})"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "execution_count": 106
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Sau khi model đã được huấn luyện và đánh giá, sử dụng hàm evaluate để lấy dự đoán\n",
        "def plot_confusion_matrix(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_flows, batch_labels, batch_lengths in test_loader:\n",
        "            batch_flows = batch_flows.to(device)\n",
        "            batch_lengths = batch_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_flows, batch_lengths)\n",
        "            outputs = outputs.view(-1)\n",
        "\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            preds = (preds > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_labels.numpy())\n",
        "\n",
        "    # Tính toán confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
        "\n",
        "    # Hiển thị confusion matrix\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Gọi hàm để hiển thị confusion matrix\n",
        "plot_confusion_matrix(model, test_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T09:36:40.090964Z",
          "iopub.execute_input": "2025-02-06T09:36:40.091334Z",
          "iopub.status.idle": "2025-02-06T09:36:40.755954Z",
          "shell.execute_reply.started": "2025-02-06T09:36:40.091302Z",
          "shell.execute_reply": "2025-02-06T09:36:40.755280Z"
        },
        "id": "Zwd_4DXMyG6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "9d8d35e8-37d3-494d-be4e-f65059fd98aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 107
    }
  ]
}